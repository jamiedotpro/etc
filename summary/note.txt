# data
# --keras                                                       # --sklearn
# model = Sequential / Models                                   # model = RandomForestClassifier()
# model.fit(x_train, y_train  ...metrics acc/mse/mae)           # model.fit(x_train, y_train)
# model.evaluate(x_test, y_test) ...return loss, acc/mse/mae    # model.score(x_test, y_test)
# model.predict(새로운 x, 새로운 y)                              # model.predict(새로운 x, 새로운 y)

--------------------------------------------------------------------------------------------------
DecisionTree, GradientBoosting, RandomForest, XGB :
장점 : 전처리 불필요
단점 : train 과적합

트리, 시계열은 범위 밖의 데이터를 잘 예측하지 못함

--------------------------------------------------------------------------------------------------
SVC
LinearSVC
KNeighborsClassfier
KNeighborsRegressor

RandomForestClassifier
RandomForestRegressor

from sklearn.linear_model import LinearRegression, Ridge, Lasso,

컬럼의 중요도 분석
DT, RF, GB, XGB

비지도
PCA 컬럼축소
autoencoder y값 없이 예측 (x값만 사용)

--------------------------------------------------------------------------------------------------
Keras Regression Metrics
Below is a list of the metrics that you can use in Keras on regression problems.

Mean Squared Error: mean_squared_error, MSE or mse
Mean Absolute Error: mean_absolute_error, MAE, mae
Mean Absolute Percentage Error: mean_absolute_percentage_error, MAPE, mape
Cosine Proximity: cosine_proximity, cosine

--------------------------------------------------------------------------------------------------
Keras Classification Metrics
Below is a list of the metrics that you can use in Keras on classification problems.

Binary Accuracy: binary_accuracy, acc
Categorical Accuracy: categorical_accuracy, acc
Sparse Categorical Accuracy: sparse_categorical_accuracy
Top k Categorical Accuracy: top_k_categorical_accuracy (requires you specify a k parameter)
Sparse Top k Categorical Accuracy: sparse_top_k_categorical_accuracy (requires you specify a k parameter)